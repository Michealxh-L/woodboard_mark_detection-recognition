{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"digit_recognition.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"f4eovUAKecw1"},"source":["# Digit Recognition"]},{"cell_type":"markdown","metadata":{"id":"AeVrWEYKecxB"},"source":["Digit racognition using CNN.\n","\n","I am using data from analytics vidya digit recognition competition."]},{"cell_type":"markdown","metadata":{"id":"AwwJ-4CvecxC"},"source":["## Importing required libraries"]},{"cell_type":"code","metadata":{"trusted":true,"id":"duIX0sY7ecxD","executionInfo":{"status":"ok","timestamp":1610823449797,"user_tz":-60,"elapsed":632,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["import pandas as pd\n","import numpy as  np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EL0r5uobecxE"},"source":["* **pandas** - we use pandas to handle our csv files\n","* **matplotlib & seaborn** - used for charting and plotting"]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"Acbd6Ht9ecxE","executionInfo":{"status":"ok","timestamp":1610823452672,"user_tz":-60,"elapsed":598,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hrh1GX5QecxF"},"source":["* **sklearn** - Popular ML library.We will use it for splitting our data."]},{"cell_type":"code","metadata":{"trusted":true,"id":"7giSjwrSecxF","executionInfo":{"status":"ok","timestamp":1610823456668,"user_tz":-60,"elapsed":2625,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["from keras.utils.np_utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\n","from keras.optimizers import RMSprop,Adam\n","from keras.callbacks import ReduceLROnPlateau"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3qANYkVZecxF"},"source":["* **Keras** : Popular Deep learning library,we will use it to build our CNN Network."]},{"cell_type":"markdown","metadata":{"id":"F2Qzfl8ZecxF"},"source":["## Loading data"]},{"cell_type":"code","metadata":{"id":"afeq0lm5kfjq","executionInfo":{"status":"ok","timestamp":1610823631720,"user_tz":-60,"elapsed":1133,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["import cv2\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import tensorflow as tf\r\n","from tensorflow.keras import datasets, layers, models"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl0r7KqQkbwD","executionInfo":{"status":"ok","timestamp":1610823666153,"user_tz":-60,"elapsed":1254,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["mnist = tf.keras.datasets.mnist\r\n","(x_train,y_train),(x_test,y_test) = mnist.load_data()\r\n","\r\n","train_X = tf.keras.utils.normalize(x_train, axis = 1)\r\n","test_X = tf.keras.utils.normalize(x_test, axis = 1)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4cEGu-8pecxG"},"source":["## Understanding the train and test data"]},{"cell_type":"code","metadata":{"trusted":true,"id":"x9HdN8xNecxG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610823668545,"user_tz":-60,"elapsed":579,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}},"outputId":"3e102e9a-3d7b-4f4b-eb0d-fdb2e87b2497"},"source":["print('Train dataset has {} rows and {} columns'.format(train_X.shape[0],train_X.shape[1]))\n","print('test dataset has {} rows and {} columns'.format(test_X.shape[0],test_X.shape[1]))\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train dataset has 60000 rows and 28 columns\n","test dataset has 10000 rows and 28 columns\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"d0X4QbPnecxH","executionInfo":{"status":"ok","timestamp":1610823696980,"user_tz":-60,"elapsed":621,"user":{"displayName":"Michael Liu","photoUrl":"","userId":"02733064710492187256"}}},"source":["train_X.head()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"A2sZ25e8ecxH"},"source":["test_X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JL7bRbizecxH"},"source":["**Pixel 0 to Pixel 783**: These are the pixel values of the image metrics.That is each row contains 28 * 28 = 784 (0-783 here) values here.Each one of these values indicates the pixel value at i x 28 + j th pixel position in the image metric."]},{"cell_type":"markdown","metadata":{"id":"HqTvrE_uecxH"},"source":["**train_y** file contains a target value i.e **label** for train data\n"]},{"cell_type":"code","metadata":{"trusted":true,"id":"SbIkuSSXecxH"},"source":["train_y.head()\n","train_y = train_y.iloc[:,1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"rhcRe1XDecxI"},"source":["\n","train_y.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhmzEwp5ecxI"},"source":["## Checking Target class distribution."]},{"cell_type":"code","metadata":{"trusted":true,"id":"IcBqNt_DecxI"},"source":["y = train_y.value_counts()\n","sns.barplot(y.index,y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iwZG4_svecxI"},"source":["## Normalize pixel values\n","\n","For most image data, the pixel values are integers with values between 0 and 255.\n","\n","Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n","\n","It is valid for images to have pixel values in the range 0-1 and images can be viewed normally.\n","\n","This can be achieved by dividing all pixels values by the largest pixel value; that is 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the image."]},{"cell_type":"code","metadata":{"trusted":true,"id":"UOxpSnUpecxJ"},"source":["train_X = train_X /255\n","test_X =test_X /255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HbNPcOY9ecxJ"},"source":["## Reshape"]},{"cell_type":"code","metadata":{"trusted":true,"id":"2YBG1yjKecxJ"},"source":["train_X= train_X.values.reshape(-1,28,28,1)\n","test_X = test_X.values.reshape(-1,28,28,1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"57vbcUtuecxJ"},"source":["print('The shape of train set now is',train_X.shape)\n","print('The shape of test set now is',test_X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lt0Q1njvecxK"},"source":["## Encoding Target Values\n","\n","\n","\n","Now we will encode our target value.Keras inbuild library to_categorical() is used to do the on-hot encoding."]},{"cell_type":"code","metadata":{"trusted":true,"id":"BbNxPEkKecxK"},"source":["train_y = to_categorical(train_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQuDhUtWecxK"},"source":["## Splitting train and test data\n","\n","Now we will split out training data into train and validation data. 20 percent of the training data will be used for validation purpose."]},{"cell_type":"code","metadata":{"trusted":true,"id":"nfwmdm9mecxK"},"source":["X_train,X_test,y_train,y_test = train_test_split(train_X,train_y,random_state = 42 , test_size=0.20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"XZzG7vyuecxK"},"source":["plt.imshow(X_train[0][:,:,0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zsENgNTFecxL"},"source":["## Generating more data"]},{"cell_type":"markdown","metadata":{"id":"fSbEuftFecxL"},"source":["In order to avoid overfitting problem , we need to expand our dataset artificially.\n","\n","We can do it by some **data augmentation techniques**.\n","\n","By applying these techniques we can double or triple the number of training examples and create a very robust model."]},{"cell_type":"code","metadata":{"trusted":true,"id":"E6kw-dT9ecxL"},"source":["datagen = ImageDataGenerator(\n","            featurewise_center = False, # set input mean to 0 over the dataset\n","            samplewise_center = False,  # set each sample mean to 0\n","            featurewise_std_normalization = False, # divide inputs by std of the dataset\n","            samplewise_std_normalization = False,  # divide each input by its std\n","            zca_whitening = False,   # apply ZCA whitening\n","            rotation_range = 10,     # randomly rotate images in the range (degrees, 0 to 180)\n","            zoom_range = 0.1,       # Randomly zoom image \n","            width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n","            height_shift_range = 0.1, # randomly shift images vertically (fraction of total height)\n","            horizontal_flip = False,  # randomly flip images\n","            vertical_flip = False     # randomly flip images\n",")\n","\n","datagen.fit(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uh0RbxT7ecxL"},"source":["I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9."]},{"cell_type":"markdown","metadata":{"id":"4-ueONxWecxM"},"source":["## Modelling\n","\n","### CNN"]},{"cell_type":"code","metadata":{"trusted":true,"id":"CVStjhCuecxM"},"source":["model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n","\n","model.add(BatchNormalization(momentum = .05))\n","\n","model.add(MaxPool2D(pool_size=(2,2)))\n","\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n","model.add(BatchNormalization(momentum=0.05))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n","model.add(BatchNormalization(momentum=.05))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = 'relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(10, activation = \"softmax\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"u_g-FlYbecxM"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0073c97ecxM"},"source":["## Optimizer\n","\n","\n","In simpler terms, optimizers shape and mold your model into its most accurate possible form by futzing with the weights. The loss function is the guide to the terrain, telling the optimizer when itâ€™s moving in the right or wrong direction."]},{"cell_type":"code","metadata":{"trusted":true,"id":"XNtaFCf2ecxN"},"source":["optimizer = Adam(learning_rate=0.001 , beta_1=0.9 ,beta_2 = 0.999)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"p4fZ2AY4ecxN"},"source":["model.compile(optimizer=optimizer , loss=['categorical_crossentropy'],metrics = ['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0I_WPFf8ecxN"},"source":["## Leraning rate reduction\n","\n","\n","\n","In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n","\n","With the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs."]},{"cell_type":"code","metadata":{"trusted":true,"id":"wrTHuXvUecxN"},"source":["learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n","                                            patience = 5 ,\n","                                            verbose = 1,\n","                                            factor = 0.5 , \n","                                            min_lr = 0.00001)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XzwbALHbecxO"},"source":["## Fitting Our Model"]},{"cell_type":"code","metadata":{"trusted":true,"id":"oRPbZwclecxO"},"source":["epochs = 20\n","batch_size = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wB0MipqWecxO"},"source":["history = model.fit_generator(datagen.flow(X_train,y_train,batch_size = batch_size),\n","                              epochs = epochs ,\n","                              validation_data = (X_test,y_test),\n","                              verbose = 2,\n","                              steps_per_epoch = X_train.shape[0]//batch_size,\n","                              callbacks =[learning_rate_reduction])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pP2lqAUgecxO"},"source":["## Evaluatin our approach using graph"]},{"cell_type":"code","metadata":{"trusted":true,"id":"9YAYDZJrecxP"},"source":["fig,ax=plt.subplots(2,1)\n","fig.set\n","x=range(1,1+epochs)\n","ax[0].plot(x,history.history['loss'],color='red')\n","ax[0].plot(x,history.history['val_loss'],color='blue')\n","\n","ax[1].plot(x,history.history['accuracy'],color='red')\n","ax[1].plot(x,history.history['val_accuracy'],color='blue')\n","ax[0].legend(['trainng loss','validation loss'])\n","ax[1].legend(['trainng acc','validation acc'])\n","plt.xlabel('Number of epochs')\n","plt.ylabel('accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qk4NWNcUecxP"},"source":["## Confusion Matrix"]},{"cell_type":"code","metadata":{"trusted":true,"id":"chycuVC5ecxP"},"source":["y_pre_test=model.predict(X_test)\n","y_pre_test=np.argmax(y_pre_test,axis=1)\n","y_test=np.argmax(y_test,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"KOU1HdDfecxP"},"source":["conf=confusion_matrix(y_test,y_pre_test)\n","conf=pd.DataFrame(conf,index=range(0,10),columns=range(0,10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"vrvS41xeecxQ"},"source":["\n","\n","conf\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"HyvOOoFrecxQ"},"source":["plt.figure(figsize=(8,6))\n","sns.set(font_scale=1.4)#for label size\n","sns.heatmap(conf, annot=True,annot_kws={\"size\": 16},cmap=plt.cm.Blues)# font size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMLPBQtcecxQ"},"source":["## Some Misclassified Images"]},{"cell_type":"code","metadata":{"trusted":true,"id":"J2--SN-7ecxQ"},"source":["x=(y_pre_test-y_test!=0).tolist()\n","x=[i for i,l in enumerate(x) if l!=False]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"GoSSCbk1ecxQ"},"source":["fig,ax=plt.subplots(1,4,sharey=False,figsize=(15,15))\n","\n","for i in range(4):\n","    ax[i].imshow(X_test[x[i]][:,:,0])\n","    ax[i].set_xlabel('Real {}, Predicted {}'.format(y_test[x[i]],y_pre_test[x[i]]))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAnTIaeeecxR"},"source":["## Predicting for test data"]},{"cell_type":"code","metadata":{"trusted":true,"id":"TZvi_m-HecxR"},"source":["y_pre_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"kIFVVZTpecxR"},"source":["test_y = model.predict(test_X)\n","test_y =np.argmax(test_y,axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"8rACZXAXecxR"},"source":["test_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WChEFnaJecxR"},"source":["test1 = test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"fhTk4K3secxS"},"source":["test1 = test1.iloc[:,0:1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"15u4PzX2ecxS"},"source":["test1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"O4XicmkUecxS"},"source":["output = pd.DataFrame({'filename': test1.iloc[1:,0],\n","                     'label': test_y})\n","output.to_csv('submission1.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"trusted":true,"id":"H_kdBq5qecxS"},"source":["Reference and credit:\n","\n","1.[Analytics Vidya](http://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/)\n","\n","2.[Kaggle notebook](http://www.kaggle.com/shahules/indian-way-to-learn-cnn)\n","\n"]}]}